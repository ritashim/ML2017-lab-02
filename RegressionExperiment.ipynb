{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Function\n",
    "## Sigmoid\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "## Logistic\n",
    "def logi(x,omg):\n",
    "    # Input - X matrix, Omega List\n",
    "    # Output - Logistic, as a list\n",
    "    return sig(np.dot(x,omg))\n",
    "\n",
    "## Loss\n",
    "def loss(x,y,omg):\n",
    "    # Input - X matrix, Y matrix, Omega List\n",
    "    # Output - Loss, as a float\n",
    "    ## Calculate: AVERAGE loss for all sample\n",
    "    return np.mean(-y*np.log(logi(x,omg)-(1-y)*np.log(1-logi(x,omg))))\n",
    "\n",
    "## Gradient\n",
    "def gra(x,y,omg):\n",
    "    # Input - X matrix, Y matrix, Omega List\n",
    "    # Output - Gradient, as a list\n",
    "    ## Calculate: Gradient for all omega\n",
    "    return np.dot(x.T,(logi(x,omg)-y)/y.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "# Parameters, overall\n",
    "## Learning rate\n",
    "learning_Rate = 0.01\n",
    "\n",
    "## Iteration count\n",
    "iter_num = 1000\n",
    "\n",
    "## SGP Batch size\n",
    "batch_size = 325\n",
    "\n",
    "# Parameters, definition of specific method\n",
    "## NAG\n",
    "NAG_v = np.zeros(124)\n",
    "NAG_alpha = 0.9\n",
    "\n",
    "## RMSProp\n",
    "RMS_rho = 0.95\n",
    "RMS_ep = 0.0000001\n",
    "\n",
    "## AdaDelta\n",
    "Ada_rho = 0.95\n",
    "Ada_ep = 0.0000001\n",
    "\n",
    "## Adam\n",
    "Adam_rho1 = 0.9\n",
    "Adam_rho2 = 0.999\n",
    "Adam_ep = 0.0000001\n",
    "\n",
    "\n",
    "\n",
    "# Data, Load\n",
    "## Train\n",
    "X_t, y_t = load_svmlight_file(\"a9a\")\n",
    "X_t = X_t.toarray()\n",
    "X_t = np.column_stack((X_t, np.ones(X_t.shape[0])))  # Add omega[0] column\n",
    "y_t = y_t + np.ones(y_t.size)\n",
    "y_t = y_t / 2  # Trans y to 1 and 0 for calculation\n",
    "\n",
    "## Test\n",
    "X_v, y_v = load_svmlight_file(\"a9a.t\")\n",
    "X_v = X_v.toarray()\n",
    "X_v = np.column_stack((X_v, np.zeros(X_v.shape[0]))) # Stupid data\n",
    "X_v = np.column_stack((X_v, np.ones(X_v.shape[0])))\n",
    "y_v = y_v + np.ones(y_v.size)\n",
    "y_v = y_v / 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data, Record\n",
    "## Loss data\n",
    "loss_NAG = []\n",
    "loss_RMSProp = []\n",
    "loss_AdaDelta = []\n",
    "loss_Adam = []\n",
    "\n",
    "## Omega\n",
    "omega_NAG = np.zeros(124)\n",
    "omega_RMSProp = np.zeros(124)\n",
    "omega_AdaDelta = np.zeros(124)\n",
    "omega_Adam = np.zeros(124)\n",
    "\n",
    "## Gradient\n",
    "gra_NAG = np.zeros(124)\n",
    "gra_RMSProp = np.zeros(124)\n",
    "gra_AdaDelta = np.zeros(124)\n",
    "gra_Adam = np.zeros(124)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data, additional definition of specific method\n",
    "## NAG\n",
    "NAG_mom = np.zeros(124)\n",
    "\n",
    "## RMSProp\n",
    "RMS_t = 0\n",
    "RMS_g = 0\n",
    "RMS_d = np.ones(124) / batch_size\n",
    "\n",
    "## AdaDelta\n",
    "Ada_t = 0\n",
    "Ada_g = 0\n",
    "Ada_d = np.ones(124) / batch_size\n",
    "\n",
    "## Adam\n",
    "Adam_v = 0\n",
    "Adam_d = np.ones(124)\n",
    "Adam_m = np.zeros(124)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Main Program ###\n",
    "# 1 - Do the calculation\n",
    "for iter in range(iter_num):\n",
    "    # Picking Random Sample\n",
    "    X_tr = np.array([])\n",
    "    y_tr = []\n",
    "    for n in range(batch_size):\n",
    "        pick = random.randint(0,y_t.shape[0]-1)\n",
    "        X_tr = np.append(X_tr, X_t[pick])\n",
    "        y_tr = np.append(y_tr, y_t[pick])\n",
    "    X_tr = X_tr.reshape(-1, 124)\n",
    "\n",
    "    # Calculate gradient\n",
    "    gra_NAG = gra(X_tr, y_tr, omega_NAG + NAG_alpha * NAG_mom)\n",
    "    gra_RMSProp = gra(X_tr, y_tr, omega_RMSProp)\n",
    "    gra_AdaDelta = gra(X_tr, y_tr, omega_AdaDelta)\n",
    "    gra_Adam = gra(X_tr, y_tr, omega_Adam)\n",
    "\n",
    "    # Do the omega calculation for each method\n",
    "    ## NAG\n",
    "    NAG_mom = -learning_Rate * gra_NAG + NAG_alpha * NAG_mom\n",
    "\n",
    "    ## RMSProp\n",
    "    RMS_t = (1-RMS_rho)*np.dot(RMS_d,RMS_d) + RMS_rho*RMS_t\n",
    "    RMS_g = (1-RMS_rho)*np.dot(gra_RMSProp,gra_RMSProp) + RMS_rho*RMS_g\n",
    "    RMS_d = -gra_RMSProp * learning_Rate / np.sqrt(RMS_g+RMS_ep)\n",
    "\n",
    "    ## AdaDelta\n",
    "    Ada_t = (1-Ada_rho)*np.dot(Ada_d,Ada_d) + Ada_rho*Ada_t\n",
    "    Ada_g = (1-Ada_rho)*np.dot(gra_AdaDelta,gra_AdaDelta) + Ada_rho*Ada_g\n",
    "    Ada_d = -gra_AdaDelta * (np.sqrt(Ada_t+Ada_ep)/np.sqrt(Ada_g+Ada_ep))\n",
    "\n",
    "    ## Adam\n",
    "    Adam_m = (1-Adam_rho1)*gra_Adam+Adam_rho1*Adam_m\n",
    "    Adam_v = (1-Adam_rho2) * np.dot(gra_Adam,gra_Adam)+Adam_rho2*Adam_v\n",
    "    Adam_d = -learning_Rate/(Adam_ep+np.sqrt(Adam_v/(1-np.power(Adam_rho2,iter+1))))*(Adam_m/(1-np.power(Adam_rho1,iter+1)))\n",
    "\n",
    "    # Do the omega updating\n",
    "    omega_NAG = omega_NAG+NAG_mom\n",
    "    omega_RMSProp = omega_RMSProp+RMS_d\n",
    "    omega_AdaDelta = omega_AdaDelta+Ada_d\n",
    "    omega_Adam = omega_Adam+Adam_d\n",
    "\n",
    "    # Calculate loss\n",
    "    loss_NAG.append(loss(X_v,y_v,omega_NAG))\n",
    "    loss_RMSProp.append(loss(X_v,y_v,omega_RMSProp))\n",
    "    loss_AdaDelta.append(loss(X_v,y_v,omega_AdaDelta))\n",
    "    loss_Adam.append(loss(X_v, y_v, omega_Adam))\n",
    "\n",
    "    # Print the loss\n",
    "    print(\"Iter%d: NAG - %.3f; RMSProp - %.3f; AdaDelta - %.3f; Adam - %.3f\" % (iter, loss_NAG[iter], loss_RMSProp[iter], loss_AdaDelta[iter], loss_Adam[iter]))\n",
    "\n",
    "# 2 - Generating the graph\n",
    "plt.plot(loss_NAG, label='NAG')\n",
    "plt.plot(loss_RMSProp, label = 'RMSProp')\n",
    "plt.plot(loss_AdaDelta, label = 'AdaDelta')\n",
    "plt.plot(loss_Adam, label = 'Adam')\n",
    "\n",
    "plt.xlabel(\"Iter\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
